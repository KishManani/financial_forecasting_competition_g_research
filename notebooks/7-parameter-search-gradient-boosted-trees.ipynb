{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/km1308/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "\n",
    "# Importing from my own modules\n",
    "import sys\n",
    "sys.path.append('../financial_forecasting/')\n",
    "from utils import load_data, wMSE, train_and_test_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/preprocessed/train.csv')\n",
    "X_val = pd.read_csv('../data/preprocessed/validation.csv')\n",
    "X_test = pd.read_csv('../data/preprocessed/test.csv')\n",
    "\n",
    "weights_train = pd.read_csv('../data/preprocessed/train_weights.csv', squeeze=True)\n",
    "weights_val = pd.read_csv('../data/preprocessed/validation_weights.csv', squeeze=True)\n",
    "\n",
    "y_train = pd.read_csv('../data/preprocessed/train_target.csv', squeeze=True)\n",
    "y_val = pd.read_csv('../data/preprocessed/validation_target.csv', squeeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomised search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom scoring function\n",
    "def eval_error(y, y_pred, weights): \n",
    "    err = wMSE(preds=y_pred, y=y, weights=weights)\n",
    "    return err\n",
    "\n",
    "my_new_score = make_scorer(eval_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], \n",
    "             'min_child_weight': [1,3,5],\n",
    "             'gamma': 10.**(-np.random.rand(15)*5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(n_estimators=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RCV = RandomizedSearchCV(model, \n",
    "                         cv_params, \n",
    "                         scoring = my_new_score, \n",
    "                         cv = 2, \n",
    "                         n_jobs = 2,\n",
    "                         n_iter=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RCV.fit(X_train, y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to slow machine I experiment with some hyperparamter tuning by hand, for fun mostly. I manage to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats= ['Day', 'Market', 'Market_mean_encoded', 'Stock', 'Stock_mean_encoded',\n",
    "       'x0', 'x0_log10', 'x0_log10_diff', 'x1_log10', 'x1_log10_diff',\n",
    "       'x2_log10', 'x2_log10_diff', 'x3A', 'x3A_log10', 'x3A_log10_diff',\n",
    "       'x3B', 'x3B_binned', 'x3B_log10', 'x3C', 'x3C_log10', 'x3D',\n",
    "       'x3D_log10', 'x3D_log10_diff', 'x3E', 'x3E_log10', 'x3E_log10_diff',\n",
    "       'x4', 'x4_binned', 'x4_log10_diff', 'x5', 'x5_binned', 'x5_log10',\n",
    "       'x5_log10_diff', 'x6', 'x6_binned', 'x6_log10_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=700, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=10.0, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.314701647653596e-07 Test error: 9.790427422658719e-07 \n",
      "\n",
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=3, missing=None, n_estimators=700, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.020348082212422e-07 Test error: 9.857127349738416e-07 \n",
      "\n",
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=6, missing=None, n_estimators=700, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.036949497655766e-07 Test error: 9.87120835202154e-07 \n",
      "\n",
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=10, missing=None, n_estimators=700, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.130197070899481e-07 Test error: 9.83910722154178e-07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "enabled_vars = feats\n",
    "\n",
    "models = OrderedDict([\n",
    "                          ('xgboost_reg1', xgb.sklearn.XGBRegressor(n_estimators=700, n_jobs=-1, reg_lambda=10.0, max_depth=5,grow_policy='lossguide', tree_method='hist')), \n",
    "                          ('xgboost_reg2', xgb.sklearn.XGBRegressor(n_estimators=700, n_jobs=-1, max_depth=5, min_child_weight=3, grow_policy='lossguide', tree_method='hist')), \n",
    "                          ('xgboost_reg3', xgb.sklearn.XGBRegressor(n_estimators=700, n_jobs=-1, max_depth=5, min_child_weight=6, grow_policy='lossguide', tree_method='hist')), \n",
    "                          ('xgboost_reg4', xgb.sklearn.XGBRegressor(n_estimators=700, n_jobs=-1, max_depth=5, min_child_weight=10, grow_policy='lossguide', tree_method='hist')), \n",
    "                    ])\n",
    "\n",
    "df_preds_train, df_preds_test, train_error, test_error = train_and_test_models(models, \n",
    "                                                         X_train.loc[:,enabled_vars], y_train, \n",
    "                                                         X_val.loc[:,enabled_vars], y_val, \n",
    "                                                         weights_train, weights_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=10, missing=None, n_estimators=800, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=10.0, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.235247638767495e-07 Test error: 9.80718041617954e-07 \n",
      "\n",
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=10, missing=None, n_estimators=700, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=10.0, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.235247638767495e-07 Test error: 9.80718041617954e-07 \n",
      "\n",
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=10, missing=None, n_estimators=600, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=10.0, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.235247638767495e-07 Test error: 9.80718041617954e-07 \n",
      "\n",
      "Fitting: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, grow_policy='lossguide',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=10, missing=None, n_estimators=500, n_jobs=-1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=10.0, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1, tree_method='hist')\n",
      "Train error: 8.418717325072864e-07 Test error: 9.81982553087281e-07 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "enabled_vars = feats\n",
    "\n",
    "models = OrderedDict([\n",
    "                          ('xgboost_reg0', xgb.sklearn.XGBRegressor(n_estimators=800, n_jobs=-1, reg_lambda=10.0, max_depth=5, min_child_weight=10, grow_policy='lossguide', tree_method='hist')), \n",
    "                          ('xgboost_reg1', xgb.sklearn.XGBRegressor(n_estimators=700, n_jobs=-1, reg_lambda=10.0, max_depth=5, min_child_weight=10, grow_policy='lossguide', tree_method='hist')), \n",
    "                          ('xgboost_reg2', xgb.sklearn.XGBRegressor(n_estimators=600, n_jobs=-1, reg_lambda=10.0, max_depth=5, min_child_weight=10, grow_policy='lossguide', tree_method='hist')), \n",
    "                          ('xgboost_reg3', xgb.sklearn.XGBRegressor(n_estimators=500, n_jobs=-1, reg_lambda=10.0, max_depth=5, min_child_weight=10, grow_policy='lossguide', tree_method='hist')), \n",
    "                    ])\n",
    "\n",
    "df_preds_train, df_preds_test, train_error, test_error = train_and_test_models(models, \n",
    "                                                         X_train.loc[:,enabled_vars], y_train, \n",
    "                                                         X_val.loc[:,enabled_vars], y_val, \n",
    "                                                         weights_train, weights_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
